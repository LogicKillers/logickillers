{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ba8d26ca-04fd-4dd0-889d-6618790fd065",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Logistic Regression:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49063d4a-12a4-451e-80d1-6f07c910cb48",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# create the model\n",
    "model = LogisticRegression(penalty='l2', C=1)\n",
    "\n",
    "# fit the model on the training data\n",
    "model.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5872620-b0ff-4162-bd24-8feaa5fcd37d",
   "metadata": {},
   "source": [
    "# Decision Tree:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44c5785e-a5d4-4e1c-85b5-64bbea1f6154",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# create the model\n",
    "model = DecisionTreeClassifier(criterion='entropy', max_depth=5, random_state=0)\n",
    "\n",
    "# fit the model on the training data\n",
    "model.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad4b92fd-4c69-43c2-bf74-de00a43ae020",
   "metadata": {},
   "source": [
    "# Random Forest:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf6e6cc4-9e8c-4617-88a0-904a5373f871",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# create the model\n",
    "model = RandomForestClassifier(n_estimators=100, criterion='entropy', random_state=0)\n",
    "\n",
    "# fit the model on the training data\n",
    "model.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "862ae043-1eb2-4922-b84f-aea00fe706be",
   "metadata": {},
   "source": [
    "# Support Vector Machine (SVM):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57214c3d-40d6-4c54-90f0-a221727e06de",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "# create the model\n",
    "model = SVC(kernel='rbf', C=1, random_state=0)\n",
    "\n",
    "# fit the model on the training data\n",
    "model.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dac86dcb-f1af-4286-b144-b8fb69a12a21",
   "metadata": {},
   "source": [
    "# K-Nearest Neighbors (KNN):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f52eb563-3d07-4b16-962b-5529b4cff52f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# create the model\n",
    "model = KNeighborsClassifier(n_neighbors=5, metric='minkowski', p=2)\n",
    "\n",
    "# fit the model on the training data\n",
    "model.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06e31071-6afb-4419-bbea-c83816a77317",
   "metadata": {},
   "source": [
    "# Naive Bayes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f02ed4b8-cbf2-44f9-989a-324e87fb54be",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "# create the model\n",
    "model = GaussianNB()\n",
    "\n",
    "# fit the model on the training data\n",
    "model.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be756485-3e61-4a26-aace-6a0b48d82863",
   "metadata": {},
   "source": [
    "# XGBoost:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a805b45-4bc2-4ff4-9d32-234aaf64a8b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "# create the model\n",
    "model = xgb.XGBClassifier(n_estimators=100, max_depth=5, random_state=0)\n",
    "\n",
    "# fit the model on the training data\n",
    "model.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "603a9d90-dc1c-4ee7-91ef-e8b93bff69df",
   "metadata": {},
   "source": [
    "# LightGBM:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28360b25-f76b-4b07-a2c0-31814720084f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "\n",
    "# create the model\n",
    "model = lgb.LGBMClassifier(n_estimators=100, max_depth=5, random_state=0)\n",
    "\n",
    "# fit the model on the training data\n",
    "model.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8993e09-e1d6-4bc0-a82d-4a84ee3a480a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "49c811bb-428c-428c-b7c0-00f525679460",
   "metadata": {},
   "source": [
    "# Ensable models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d775ad3-ccee-445e-b132-b78218be8b47",
   "metadata": {},
   "source": [
    "## Bagging:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65475fb2-c3a6-419b-a5c7-8e3090a54b8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# create the base model\n",
    "base_model = DecisionTreeClassifier(criterion='entropy', max_depth=5, random_state=0)\n",
    "\n",
    "# create the ensemble model\n",
    "ensemble_model = BaggingClassifier(base_estimator=base_model, n_estimators=100, random_state=0)\n",
    "\n",
    "# fit the ensemble model on the training data\n",
    "ensemble_model.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43d77a4a-1287-4eb1-9edf-778a1dd5e06e",
   "metadata": {},
   "source": [
    "## Boosting:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6acfa46-5e3e-4579-b8f4-63a4823c869a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# create the base model\n",
    "base_model = DecisionTreeClassifier(random_state=0)\n",
    "\n",
    "# create the ensemble model\n",
    "model = AdaBoostClassifier(base_estimator=base_model, n_estimators=100, random_state=0)\n",
    "\n",
    "# fit the model on the training data\n",
    "model.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "058b7f0b-db60-4287-ae29-e7cb666112a0",
   "metadata": {},
   "source": [
    "## Random Forest:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f9e9ee5-fd13-4b3c-af0f-051a32a24b2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# create the model\n",
    "model = RandomForestClassifier(n_estimators=100, criterion='entropy', random_state=0)\n",
    "\n",
    "# fit the model on the training data\n",
    "model.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08c9f676-7eb7-42d6-8623-fc77c91c70d8",
   "metadata": {},
   "source": [
    "## Gradient Boosting:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa8d0fbf-c969-4cd3-92c5-e9cd4068777f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "# create the model\n",
    "model = GradientBoostingClassifier(n_estimators=100, random_state=0)\n",
    "\n",
    "# fit the model on the training data\n",
    "model.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eb03721-90f6-49c1-9b66-e54642dc6aba",
   "metadata": {},
   "source": [
    "## XGBoost:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f6ac93b-80b3-4982-9148-4ace2787dbea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "# create the model\n",
    "model = xgb.XGBClassifier(n_estimators=100, max_depth=5, random_state=0)\n",
    "\n",
    "# fit the model on the training data\n",
    "model.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "465f382e-8f27-40a1-8fbc-394a5b2a74f4",
   "metadata": {},
   "source": [
    "## Stacking:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b16a3425-fbba-4467-892f-4ef84c563216",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import StackingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# create the base models\n",
    "base_models = [LogisticRegression(random_state=0), DecisionTreeClassifier(random_state=0)]\n",
    "\n",
    "# create the ensemble model\n",
    "model = StackingClassifier(estimators=base_models, final_estimator=LogisticRegression(random_state=0))\n",
    "\n",
    "# fit the model on the training data\n",
    "model.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4366bf9e-9237-4375-b602-c43fe6b646f5",
   "metadata": {},
   "source": [
    "## Voting Classifier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "624489e4-d49b-4327-82dc-a54da99cc465",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# create the base models\n",
    "base_models = [('lr', LogisticRegression(random_state=0)), ('dt', DecisionTreeClassifier(random_state=0))]\n",
    "\n",
    "# create the ensemble model\n",
    "model = VotingClassifier(estimators=base_models, voting='hard')\n",
    "\n",
    "# fit the model on the training data\n",
    "model.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65e8762f-de2c-4392-bae1-68f78b3db3c1",
   "metadata": {},
   "source": [
    "## Blending:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23e354a0-c774-434d-9b49-17a592f108b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# train base models\n",
    "base_model1 = LogisticRegression(random_state=0)\n",
    "base_model1.fit(X_train, y_train)\n",
    "\n",
    "base_model2 = DecisionTreeClassifier(random_state=0)\n",
    "base_model2.fit(X_train, y_train)\n",
    "\n",
    "# blend predictions\n",
    "predictions = 0.5*base_model1.predict_proba(X_test) + 0.5*base_model2.predict_proba(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ab1d51f-9285-49c3-826b-16f9117bfd80",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "75d83efc-eeef-4cb8-85b3-5336f85f6ea1",
   "metadata": {},
   "source": [
    "# Hyper parameter tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85e6f304-4583-4182-9d1c-f8f5a36964fc",
   "metadata": {},
   "source": [
    "## Grid Search:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d09ddfd-2d18-4270-92aa-1f2a2e84dc16",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# define the hyperparameters and their possible values\n",
    "param_grid = {'C': [0.1, 1, 10], 'penalty': ['l1', 'l2']}\n",
    "\n",
    "# create the model\n",
    "model = LogisticRegression()\n",
    "\n",
    "# create the grid search\n",
    "grid_search = GridSearchCV(model, param_grid, cv=5)\n",
    "\n",
    "# fit the grid search on the data\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# get the best hyperparameters\n",
    "best_params = grid_search.best_params_\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30f596b4-f1d8-49fc-8784-a852c3436595",
   "metadata": {},
   "source": [
    "## Random Search:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "635b855d-bc0a-418c-b115-d2b814d9492c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from scipy.stats import uniform\n",
    "\n",
    "# define the hyperparameters and their possible values\n",
    "param_grid = {'C': uniform(0, 10), 'penalty': ['l1', 'l2']}\n",
    "\n",
    "# create the model\n",
    "model = LogisticRegression()\n",
    "\n",
    "# create the random search\n",
    "random_search = RandomizedSearchCV(model, param_grid, cv=5, n_iter=10, random_state=0)\n",
    "\n",
    "# fit the random search on the data\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "# get the best hyperparameters\n",
    "best_params = random_search.best_params_\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a770e173-a253-4db9-8286-b1ef28e74a6c",
   "metadata": {},
   "source": [
    "## Bayesian Optimization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a5c1a8f-bd47-4b28-9c70-4db0100dc981",
   "metadata": {},
   "outputs": [],
   "source": [
    "from skopt import BayesSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from skopt.space import Real, Categorical\n",
    "\n",
    "# define the hyperparameters and their possible values\n",
    "param_grid = {'C': Real(0, 10), 'penalty': Categorical(['l1', 'l2'])}\n",
    "\n",
    "# create the model\n",
    "model = LogisticRegression()\n",
    "\n",
    "# create the bayesian optimization\n",
    "bayesian_search = BayesSearchCV(model, param_grid, n_iter=10)\n",
    "\n",
    "# fit the bayesian optimization on the data\n",
    "bayesian_search.fit(X_train, y_train)\n",
    "\n",
    "# get the best hyperparameters\n",
    "best_params = bayesian_search.best_params_\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4248bbf5-ad69-456d-b2ff-edf34910c38a",
   "metadata": {},
   "source": [
    "## Optuna:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9736afe2-31d8-48f5-ad6e-596d138b1d44",
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "def objective(trial):\n",
    "    C = trial.suggest_loguniform('C', 0.001, 10)\n",
    "    penalty = trial.suggest_categorical('penalty', ['l1', 'l2'])\n",
    "    model = LogisticRegression(C=C, penalty=penalty)\n",
    "    return optuna.integration.sklearn_integration.mean_squared_error(model, X_train, y_train)\n",
    "\n",
    "study = optuna.create_study()\n",
    "study.optimize(objective, n_trials=10)\n",
    "\n",
    "best_params = study.best_params\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cafd529f-31f0-42b3-9911-a95de3e9134c",
   "metadata": {},
   "source": [
    "Optuna is a python library to perform hyperparameter optimization tasks. It uses a technique called Tree-structured Parzen Estimator (TPE) that suggest new hyperparameters based on the previous results of the trials. It requires you to define an objective function that takes a trial object as an input and returns the evaluation metric that you want to optimize.\n",
    "\n",
    "Please note that these are just examples, and you may need to adjust the parameters to suit your specific dataset and problem. Also, depending on your problem, you may need to use different hyperparameter tuning methods or different values for the parameters.\n",
    "Also it's worth to mention that Optuna is more flexible than GridSearchCV, RandomizedSearchCV and BayesianOptimization in term of handling categorical and continuous variables, handling dependencies and constraints between variables, handling missing values, and more."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf8a5719-4d07-479c-bbe6-9b468876be61",
   "metadata": {},
   "source": [
    "## Bagging:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cd55274-ddcb-4b30-98b7-e8d231884622",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
